version: "3.1"
services:
  llama:
    command: >
      --hf-repo unsloth/Qwen3-4B-GGUF:q4_k_m
      --port 8000
      --threads 6
      --ctx-size 4096
      --flash-attn
      --batch-size 512
      --gpu-layers 999
      --host 0.0.0.0
      --device CUDA0
      --cache-type-k q8_0
      --cache-type-v q8_0
      --jinja
      --reasoning-format deepseek
      --alias "Qwen3 4B"
      --api-key ${AI_API_KEY}
    deploy:
      resources:
        reservations:
          devices:
          - capabilities: [gpu]